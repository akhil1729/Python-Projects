{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKIHLuUNy310Tj2E7UkZvj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhil1729/Python-Projects/blob/main/603_MapReduce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Date of Birth in DD-MM-YYYY format is 03-02-2000"
      ],
      "metadata": {
        "id": "Q5pZIv6zKQ52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2pvKk2AK-Gs",
        "outputId": "9ca497ef-8d8b-404b-aed0-54cc87f7f5dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspellchecker\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOuqcpHeRwCW",
        "outputId": "ecf26c5f-7791-4f5c-83c4-be37ca4417e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.10/dist-packages (0.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWemhJoCJ-uf",
        "outputId": "98e52350-647a-4d66-e5bb-2e8277a6fb82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pages successfully extracted to file.txt and file2.txt\n"
          ]
        }
      ],
      "source": [
        "import PyPDF2\n",
        "\n",
        "# Function to extract pages and save them as a text file\n",
        "def extract_pages_to_text(pdf_file, start_page, num_pages, output_file):\n",
        "    with open(pdf_file, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        extracted_text = \"\"\n",
        "\n",
        "        # Ensure the page range is valid\n",
        "        num_pages_in_pdf = len(reader.pages)\n",
        "        for i in range(start_page - 1, min(start_page - 1 + num_pages, num_pages_in_pdf)):\n",
        "            extracted_text += reader.pages[i].extract_text()\n",
        "\n",
        "        # Write the extracted text to the output file\n",
        "        with open(output_file, 'w') as txt_file:\n",
        "            txt_file.write(extracted_text)\n",
        "\n",
        "# File path for the Harry Potter PDF\n",
        "pdf_path = 'Harry_Potter_(www.ztcprep.com).pdf'\n",
        "\n",
        "# Your birth date is February 3, 2000, so we extract the following pages:\n",
        "# For the birth date (03), extract 10 pages starting from page 3 of Book 2 (Chamber of Secrets)\n",
        "book_2_start_page = 1  # Assuming book 2 starts at page 1\n",
        "extract_pages_to_text(pdf_path, book_2_start_page + 3, 10, 'file.txt')\n",
        "\n",
        "# For the birth year (2000), extract 10 pages starting from page 100 of Book 2\n",
        "extract_pages_to_text(pdf_path, book_2_start_page + 100, 10, 'file2.txt')\n",
        "\n",
        "print(\"Pages successfully extracted to file.txt and file2.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "# Function to preprocess the text by removing punctuation and converting to lowercase\n",
        "def preprocess(text_file):\n",
        "    text_file = text_file.lower()\n",
        "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text_file)  # Only keep letters and spaces\n",
        "    return cleaned_text\n",
        "\n",
        "# Mapper function to count word occurrences\n",
        "def mapper(text):\n",
        "    words = text.split()\n",
        "    word_counts = defaultdict(int)\n",
        "    for word in words:\n",
        "        word_counts[word] += 1\n",
        "    return word_counts\n",
        "\n",
        "# Reducer function to sum up word counts\n",
        "def reducer(mapped_data):\n",
        "    final_counts = defaultdict(int)\n",
        "    for word, count in mapped_data.items():\n",
        "        final_counts[word] += count\n",
        "    return final_counts\n",
        "\n",
        "# Read the file containing text\n",
        "with open('file.txt', 'r') as file:\n",
        "    text_file = file.read()\n",
        "\n",
        "# Preprocess and run MapReduce\n",
        "processed_text = preprocess(text_file)\n",
        "map_data = mapper(processed_text)\n",
        "reduce_data = reducer(map_data)\n",
        "\n",
        "# Print the word count sorted alphabetically\n",
        "sorted_dict = dict(sorted(reduce_data.items(), key=lambda x: x[0]))\n",
        "print(sorted_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjLZmYMfK0k9",
        "outputId": "83089dac-3484-4488-ee78-11eb6170af2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 52, 'about': 6, 'across': 2, 'act': 1, 'acting': 1, 'after': 1, 'afternoon': 1, 'again': 1, 'all': 6, 'allowed': 1, 'almost': 3, 'also': 2, 'although': 2, 'always': 2, 'amount': 1, 'an': 3, 'and': 41, 'angrily': 1, 'another': 1, 'any': 3, 'anyone': 1, 'anything': 2, 'anywhere': 1, 'apart': 1, 'approve': 1, 'are': 2, 'armchair': 1, 'around': 4, 'arrived': 2, 'as': 17, 'at': 15, 'away': 2, 'back': 7, 'backed': 1, 'bag': 1, 'baker': 1, 'bakery': 1, 'be': 9, 'bear': 2, 'because': 4, 'bed': 1, 'beefy': 1, 'been': 11, 'before': 2, 'behaving': 1, 'behavior': 1, 'being': 2, 'better': 1, 'big': 1, 'birds': 1, 'birdwatchers': 1, 'bit': 1, 'blame': 1, 'blinked': 1, 'blonde': 1, 'bonfire': 1, 'boring': 1, 'boy': 4, 'briefcase': 1, 'broad': 1, 'building': 1, 'bun': 1, 'bunch': 1, 'but': 12, 'buy': 1, 'by': 3, 'called': 6, 'calls': 1, 'came': 1, 'can': 1, 'car': 2, 'cat': 8, 'catch': 1, 'cats': 1, 'caught': 1, 'celebrating': 2, 'cereal': 1, 'chair': 1, 'changed': 2, 'cheek': 1, 'child': 1, 'chortled': 1, 'cloak': 2, 'cloaks': 3, 'close': 1, 'clothes': 1, 'cloudy': 1, 'clutching': 1, 'collecting': 2, 'come': 1, 'complete': 1, 'concentrate': 2, 'contrary': 1, 'corner': 3, 'could': 3, 'couldn': 4, 'country': 1, 'couple': 1, 'craning': 1, 'dashed': 1, 'daughter': 1, 'day': 3, 'daylight': 2, 'dead': 1, 'dear': 1, 'determined': 1, 'dialing': 1, 'did': 2, 'didn': 12, 'dif': 1, 'dinner': 1, 'direction': 1, 'director': 1, 'discover': 1, 'disturb': 1, 'don': 2, 'door': 2, 'doughnut': 1, 'down': 2, 'downpour': 1, 'dressed': 2, 'drills': 6, 'drive': 4, 'driven': 1, 'driveway': 1, 'drove': 2, 'drummed': 1, 'dudley': 7, 'dull': 1, 'dundee': 1, 'dursley': 31, 'dursleys': 4, 'e': 5, 'early': 1, 'ed': 1, 'edge': 1, 'eight': 1, 'ell': 1, 'else': 1, 'emeraldgreen': 1, 'enraged': 1, 'even': 5, 'evening': 1, 'ever': 1, 'every': 1, 'everything': 1, 'everywhere': 1, 'except': 1, 'excitedly': 2, 'expect': 1, 'experts': 1, 'explain': 1, 'eyed': 1, 'eyes': 2, 'f': 2, 'face': 1, 'fact': 1, 'far': 1, 'fashion': 1, 'fear': 2, 'fell': 2, 'fences': 1, 'ferent': 1, 'few': 3, 'fic': 2, 'fice': 2, 'fin': 1, 'finally': 1, 'finer': 1, 'fingers': 1, 'finished': 1, 'firm': 1, 'first': 2, 'five': 2, 'flooded': 1, 'floor': 1, 'flutter': 1, 'flying': 1, 'folks': 1, 'for': 9, 'found': 3, 'four': 3, 'from': 1, 'frozen': 1, 'funny': 1, 'g': 5, 'garden': 2, 'gave': 2, 'gazed': 1, 'ge': 4, 'get': 1, 'getups': 1, 'going': 1, 'gone': 1, 'good': 2, 'goodbye': 1, 'goodfor': 1, 'gossiped': 1, 'got': 2, 'gotten': 1, 'gray': 1, 'greatest': 1, 'grin': 1, 'ground': 1, 'group': 1, 'grunnings': 2, 'grunted': 1, 'had': 22, 'hadn': 2, 'half': 1, 'happening': 1, 'happily': 1, 'happy': 2, 'harder': 2, 'hardly': 2, 'harold': 1, 'harry': 8, 'harvey': 1, 'has': 1, 'have': 13, 'having': 1, 'he': 61, 'head': 1, 'heard': 1, 'hed': 5, 'help': 1, 'her': 6, 'high': 1, 'him': 7, 'himself': 5, 'his': 29, 'hold': 1, 'home': 2, 'hoped': 1, 'hoping': 2, 'house': 2, 'how': 1, 'however': 1, 'huddle': 1, 'hugged': 2, 'hummed': 1, 'hundreds': 1, 'hunt': 1, 'hurried': 2, 'husband': 1, 'i': 4, 'iewers': 1, 'if': 5, 'imagination': 1, 'imagining': 1, 'important': 1, 'improve': 1, 'in': 25, 'instead': 1, 'into': 7, 'involved': 1, 'it': 23, 'its': 1, 'jam': 1, 'jerked': 1, 'jim': 2, 'jk': 5, 'just': 3, 'keeping': 1, 'kent': 1, 'kiss': 1, 'knew': 1, 'knocked': 1, 'know': 2, 'knowwho': 1, 'lar': 4, 'last': 3, 'later': 1, 'learned': 1, 'left': 2, 'legs': 1, 'let': 1, 'light': 1, 'like': 3, 'little': 2, 'lived': 1, 'living': 1, 'look': 2, 'looked': 1, 'looking': 1, 'lot': 3, 'lots': 1, 'loudly': 1, 'lunchtime': 1, 'made': 4, 'man': 5, 'map': 2, 'maps': 1, 'markings': 1, 'mcguf': 1, 'me': 2, 'mention': 2, 'met': 1, 'middle': 1, 'might': 2, 'mind': 4, 'minutes': 1, 'mirror': 1, 'missed': 1, 'mixing': 1, 'mood': 2, 'more': 2, 'morning': 4, 'most': 3, 'move': 1, 'moved': 1, 'mr': 24, 'mrs': 11, 'much': 2, 'muggle': 1, 'muggles': 1, 'must': 1, 'mustache': 2, 'my': 1, 'mysterious': 3, 'name': 1, 'nation': 1, 'nearly': 1, 'neck': 2, 'neighbors': 2, 'nephew': 1, 'nerve': 1, 'never': 4, 'new': 2, 'news': 1, 'newscaster': 1, 'next': 3, 'nice': 1, 'night': 3, 'nighttime': 1, 'ninth': 1, 'no': 4, 'none': 1, 'nonsense': 1, 'normal': 4, 'normally': 2, 'not': 4, 'nothing': 4, 'noticed': 2, 'noticing': 1, 'now': 4, 'number': 4, 'obviously': 1, 'oclock': 1, 'oddly': 1, 'of': 38, 'old': 2, 'older': 1, 'on': 19, 'one': 1, 'only': 1, 'openmouthed': 1, 'opinion': 1, 'or': 3, 'order': 1, 'orkshire': 1, 'ou': 1, 'our': 1, 'out': 5, 'outside': 2, 'over': 4, 'overhead': 1, 'owl': 4, 'owlfree': 1, 'owls': 6, 'p': 5, 'parking': 1, 'passed': 2, 'passersby': 1, 'past': 4, 'pattern': 1, 'pecked': 1, 'peculiar': 1, 'people': 12, 'perfectly': 2, 'perhaps': 1, 'philosophers': 5, 'phoning': 1, 'picked': 2, 'point': 1, 'pointed': 1, 'possible': 1, 'potter': 8, 'potters': 5, 'pretended': 1, 'privet': 3, 'probably': 1, 'problems': 1, 'promise': 1, 'promised': 1, 'proud': 1, 'pull': 1, 'pulled': 1, 'put': 3, 'quite': 1, 'rain': 1, 'rattled': 1, 'read': 1, 'reading': 2, 'realize': 1, 'realized': 1, 'reason': 1, 'receiver': 1, 'rejoice': 1, 'report': 1, 'reported': 1, 'right': 1, 'road': 3, 'room': 1, 'rooted': 1, 'rowling': 5, 'rying': 1, 's': 9, 'said': 4, 'same': 3, 'sat': 3, 'saw': 2, 'say': 3, 'saying': 1, 'screaming': 1, 'second': 1, 'seconds': 1, 'secret': 1, 'secretary': 1, 'see': 3, 'seem': 1, 'seemed': 1, 'seen': 5, 'seized': 1, 'set': 1, 'several': 2, 'shake': 1, 'she': 5, 'shoo': 1, 'shooting': 2, 'should': 1, 'shouted': 1, 'showers': 1, 'shuddered': 1, 'sight': 1, 'sightings': 1, 'sign': 3, 'signs': 1, 'silly': 1, 'since': 1, 'single': 1, 'sir': 1, 'sister': 5, 'sitting': 1, 'sky': 1, 'sleeping': 1, 'small': 2, 'smile': 1, 'snapped': 1, 'so': 3, 'some': 2, 'somebody': 1, 'someone': 1, 'something': 4, 'son': 4, 'soon': 1, 'sorry': 2, 'sped': 1, 'spent': 1, 'split': 1, 'spot': 1, 'spotted': 1, 'spying': 1, 'squeaky': 1, 'standing': 2, 'stare': 1, 'stared': 2, 'stars': 2, 'starts': 1, 'steering': 1, 'stern': 1, 'still': 2, 'stone': 5, 'stood': 1, 'stopped': 1, 'story': 1, 'straight': 1, 'strange': 2, 'strangely': 1, 'stranger': 1, 'street': 3, 'stretch': 1, 'stroked': 1, 'struck': 1, 'stumbled': 1, 'stunt': 1, 'stupid': 2, 'such': 2, 'suddenly': 1, 'suggest': 1, 'sunrise': 1, 'supposed': 1, 'sure': 3, 'swooping': 1, 't': 28, 'tabby': 2, 'tantrum': 1, 'tawny': 1, 'telephone': 2, 'tell': 1, 'than': 1, 'thank': 1, 'that': 28, 'the': 86, 'their': 4, 'them': 7, 'then': 2, 'there': 8, 'these': 3, 'they': 14, 'theyve': 1, 'thin': 1, 'thing': 1, 'things': 2, 'think': 3, 'thinking': 2, 'this': 6, 'those': 1, 'though': 1, 'thought': 4, 'throwing': 1, 'tie': 1, 'time': 2, 'tin': 1, 'tiny': 1, 'to': 34, 'today': 3, 'together': 2, 'told': 1, 'tonight': 2, 'too': 2, 'toward': 1, 'town': 2, 'traf': 2, 'trick': 1, 'tried': 2, 'twice': 1, 'tyke': 1, 'uesday': 1, 'unable': 1, 'undursleyish': 1, 'uneasy': 1, 'until': 3, 'unusual': 1, 'unusually': 1, 'up': 4, 'upset': 3, 'useful': 1, 'usual': 2, 'v': 1, 'very': 5, 'violet': 1, 'voice': 1, 'w': 3, 'walk': 1, 'walked': 2, 'wall': 1, 'walls': 1, 'want': 1, 'wanted': 2, 'was': 35, 'wasn': 3, 'watched': 1, 'way': 1, 'wearing': 2, 'weather': 1, 'weatherman': 1, 'week': 1, 'weirdos': 1, 'went': 1, 'were': 10, 'weren': 1, 'wet': 1, 'what': 5, 'whatever': 1, 'wheel': 1, 'when': 5, 'which': 3, 'whisperers': 1, 'whispering': 2, 'who': 3, 'why': 3, 'wide': 1, 'wife': 1, 'window': 2, 'with': 6, 'woke': 1, 'wondered': 1, 'word': 1, 'words': 1, 'work': 1, 'worried': 1, 'worrying': 1, 'would': 4, 'wrestled': 1, 'wwwztcprepcom': 10, 'y': 2, 'years': 1, 'yelled': 1, 'yes': 2, 'yesterday': 1, 'you': 2, 'youd': 1, 'young': 2, 'yourself': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "# Initialize the spell checker\n",
        "spell = SpellChecker()\n",
        "\n",
        "# Preprocessing function: convert text to lowercase, remove punctuation, and clean text\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    words = text.split()\n",
        "    cleaned_words = [re.sub(r'^[^a-zA-Z\\']+', '', re.sub(r'[^a-zA-Z\\']+$', '', word)) for word in words]\n",
        "    return ' '.join(cleaned_words)\n",
        "\n",
        "# Mapper function to count non-English (unknown) words\n",
        "def mapper(text):\n",
        "    words = text.split()\n",
        "    output = defaultdict(int)\n",
        "    for word in words:\n",
        "        if word and spell.unknown([word]):  # If the word is not in the English dictionary\n",
        "            output[word] += 1\n",
        "    return output\n",
        "\n",
        "# Reducer function to sum up counts of non-English words\n",
        "def reducer(map_data):\n",
        "    output = defaultdict(int)\n",
        "    for word, count in map_data.items():\n",
        "        output[word] += count\n",
        "    return output\n",
        "\n",
        "# Read the file containing text to be analyzed\n",
        "with open('file2.txt', 'r') as file:\n",
        "    text_file = file.read()\n",
        "\n",
        "# Preprocess the text to clean it\n",
        "processed_text_file = preprocess(text_file)\n",
        "\n",
        "# Running MapReduce\n",
        "map_data = mapper(processed_text_file)\n",
        "reduce_data = reducer(map_data)\n",
        "\n",
        "# Print non-English words in alphabetical order\n",
        "sorted_dict = dict(sorted(reduce_data.items(), key=lambda x: x[0]))\n",
        "print(sorted_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYf-nM4eRWta",
        "outputId": "172bf571-61d4-4a96-ff16-2f8b7c03122d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'albus': 2, 'ap': 3, 'aren': 1, 'cept': 1, 'deliverin': 1, 'diagon': 1, 'didn': 6, 'dudley': 7, 'dumbled': 1, 'dumbledore': 4, 'd’yeh': 1, 'eah': 2, 'ernon': 6, 'everythin': 1, 'fetchin': 1, 'ge': 1, 'gettin': 2, 'goin': 1, 'gringotts': 5, 'hadn': 3, 'hagrid': 27, 'he’d': 3, 'he’ll': 3, 'hogwarts': 7, 'insul': 1, 'izards': 2, 'i’ll': 2, 'i’m': 2, 'i’ve': 2, 'j.k': 7, 'james': 1, 'knuts': 2, 'london': 1, 'meself': 1, 'mm': 1, 'muggle': 1, 'ou': 1, 'payin': 1, 'rowling': 7, 'shouldn': 1, 'speakin': 1, 'strange-looking': 1, 'stuf': 3, 's’pposed': 1, 'teh': 1, 'ter': 19, 'ther': 1, 'they’d': 1, 'they’re': 1, 'wasn': 2, 'we’ll': 1, 'we’ve': 1, 'wouldn': 1, 'www.ztcprep.com': 10, 'yeh': 8, 'yeh’d': 1, 'ying': 1, 'you’ll': 1}\n"
          ]
        }
      ]
    }
  ]
}